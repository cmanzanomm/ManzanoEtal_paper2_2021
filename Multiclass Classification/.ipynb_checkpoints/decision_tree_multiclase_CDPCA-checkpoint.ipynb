{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ARBOL CON multiclase BINARIA BENIGNOS Y MALWARE\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report \n",
    "import os\n",
    "import glob\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"crea entorno grÃ¡fico\"\"\"\n",
    "plt.rcParams['figure.figsize'] = (40, 50)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Primero especificamos un patrón del archivo y lo pasamos como parámetro en la función glob\n",
    "os.chdir(\"..\\\\Datasets\")\n",
    "os.getcwd()\n",
    "csv_files = glob.glob('*.csv')\n",
    "# Mostrar el archivo csv_files, el cual es una lista de nombres\n",
    "print(csv_files)\n",
    "\n",
    "list_data = []\n",
    "  \n",
    "# Escribimos un loop que irá a través de cada uno de los nombres de archivo a través de globbing y el resultado final será la lista dataframes\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "#Para chequear que todo está bien, mostramos la list_data por consola\n",
    "#list_data\n",
    " \n",
    "df = pd.concat(list_data,ignore_index=True)\n",
    "\n",
    "tipos=df.dtypes  #tipos de datos de campos\n",
    "\n",
    "\"\"\"información datos\"\"\"\n",
    "print(df.head(5))\n",
    "print('Cantidad de Filas y columnas:',df.shape)\n",
    "print('Nombre columnas:',df.columns)\n",
    "\n",
    "\"\"\"Columnas, nulos y tipo de datos\"\"\"\n",
    "print(df.info())\n",
    "\n",
    "\"\"\"descripción estadística de los datos numéricos\"\"\"\n",
    "print(df.describe())\n",
    "\n",
    "\"\"\"correlación entre los datos\"\"\"\n",
    "corr = df.set_index('Label').corr()\n",
    "#sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
    "#plt.show()\n",
    "\n",
    "df2=df[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']]\n",
    "df3=df[['Label']]\n",
    "\n",
    "\"\"\"convertir columna tipo dato str a int\"\"\"\n",
    "df2['Label']=df3[['Label']]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "bines = 4 # Elegir el número de bines\n",
    "cabecera = list(df2) # Guardamos los nombres de las columnas.\n",
    "ind = 0 # Contador para iterar por columnas.\n",
    "while (ind < len(cabecera)):\n",
    "    disc = df2.iloc[:,ind] \n",
    "    disc = disc.to_frame() \n",
    "    disc = KBinsDiscretizer(n_bins=bines, encode='ordinal',\n",
    "                            strategy = \"quantile\").fit_transform(disc)\n",
    "    df2[cabecera[ind]] = disc \n",
    "    ind = ind + 1\n",
    "    del(disc)   \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"desordena el dataset\"\"\"\n",
    "\"\"\"desordena el dataset\"\"\"\n",
    "\n",
    "df2=df2.sort_values('Fwd_Pkt_Len_Min')\n",
    "df2 = df2[df2['Label'].isin([1,2,3,4])]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" convertir valores número la clase\n",
    "df2['Label'] = df2['Label'].replace(1,\"Benigno\")\n",
    "df2['Label'] = df2['Label'].replace(2,\"Adware\")\n",
    "df2['Label'] = df2['Label'].replace(3,\"Scareware\")\n",
    "df2['Label'] = df2['Label'].replace(4,\"Ransomware\")\n",
    "#print(df2.head(10))\n",
    "#print(df2.groupby('Label').size())\n",
    "\"\"\"\n",
    "\n",
    "dff=df2[:]\n",
    "dff1 = dff[dff.Label == 4]\n",
    "dff = dff.drop(dff[dff['Label'] == 4].index)\n",
    "a = dff1.iloc[0:41100,]\n",
    "dff2 = pd.concat([dff,a])\n",
    "\n",
    "dff=dff2[:]\n",
    "dff1 = dff[dff.Label == 1]\n",
    "dff = dff.drop(dff[dff['Label'] == 1].index)\n",
    "a = dff1.iloc[0:123500,]\n",
    "dff2 = pd.concat([dff,a])\n",
    "\n",
    "print(dff2.groupby('Label').size())\n",
    "\n",
    "\"\"\"CREAMOS EL MODELO Y LO PROBAMOS CON LOS MISMOS DATOS SIN CROSS\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def clean_dataset(df):\n",
    "       assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "       df.dropna(inplace=True)\n",
    "       indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "       return df[indices_to_keep].astype(np.float64)\n",
    "clean_dataset(dff2)   \n",
    "\"\"\"\n",
    "dff2 = dff2.fillna(lambda x: x.median())\n",
    "\n",
    "\n",
    "# example of a standardization\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#scaler = StandardScaler()\n",
    "#dff2 = scaler.fit_transform(dff2)\n",
    "#trans = MinMaxScaler()\n",
    "#dff2 = trans.fit_transform(dff2)\n",
    "\n",
    "\n",
    "   \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dff2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', \n",
    "\t   ]], dff2['Label'], test_size = 0.20, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "clf2 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best')#presort=False,\n",
    "\n",
    "\n",
    "\n",
    "#entreno modelo\n",
    "\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "acc_decision_tree = round(clf2.score(X_train, Y_train) * 100, 2)\n",
    "print(\"Precisión Modelo entrenado (Accuracy) : \", acc_decision_tree, \"%\")\n",
    "acc_decision_tree = round(clf2.score(X_test, Y_test) * 100, 2)\n",
    "print(\"Precisión Modelo validado (Accuracy) : \", acc_decision_tree, \"%\")\n",
    "\n",
    "#Realizo una predicción\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "\n",
    "matriz = confusion_matrix(Y_test, y_pred2)\n",
    "print('Matriz de Confusión AD Validada :')\n",
    "print(matriz)\n",
    "\n",
    "print(\"Métricas AD Validadas\")\n",
    "print(classification_report(Y_test, y_pred2))\n",
    "\n",
    "\n",
    "\n",
    "#classifier=OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "#y_score = classifier.fit(X_train, Y_train).decision_function (X_test)\n",
    "classifier=OneVsRestClassifier(DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best'))\n",
    "y_score = classifier.fit(X_train, Y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(17, 6)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "plot_multiclass_roc(classifier, X_test, Y_test, n_classes=4, figsize=(16, 10))\n",
    "\n",
    "\n",
    "\"\"\"=============================================\"\"\"\n",
    "\"\"\" CROSS VALIDATION\"\"\"\n",
    "\n",
    "X_trainCV, X_testCV, Y_trainCV, Y_testCV = train_test_split(dff2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', \n",
    "\t   ]],dff2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "clfCV = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best')\n",
    "clfCV.fit(X_train, Y_train)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "score = clfCV.score(X_trainCV,Y_trainCV)\n",
    "print(\"Metrica del modelo\", score * 100)\n",
    "scores = cross_val_score(clfCV, X_trainCV, Y_trainCV, cv=kf, scoring=\"accuracy\")\n",
    "print(\"Metricas cross_validation\", scores * 100)\n",
    "#print(\"Media de cross_validation\", scores.mean() * 100)\n",
    "preds = clfCV.predict(X_testCV)\n",
    "score_pred = metrics.accuracy_score(Y_testCV, preds)\n",
    "print(\"Metrica en Test\", score_pred * 100)\n",
    "conf_mat = confusion_matrix(Y_testCV, preds)\n",
    "print(conf_mat)\n",
    "print(classification_report(Y_testCV, preds))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#classifierCV=OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "#y_score = classifierCV.fit(X_train, Y_train).decision_function(X_test)\n",
    "\n",
    "classifierCV=OneVsRestClassifier(DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best'))\n",
    "y_score = classifierCV.fit(X_train, Y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(17, 6)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "#plot_multiclass_roc(classifierCV, X_test, Y_test, n_classes=4, figsize=(16, 10))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dtype: int64\n",
    "Precisión Modelo entrenado (Accuracy) :  93.48 %\n",
    "Precisión Modelo validado (Accuracy) :  93.45 %\n",
    "Matriz de Confusión AD Validada :\n",
    "[[26036  1556]\n",
    " [ 1233 13734]]\n",
    "Métricas AD Validadas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.95      0.94      0.95     27592\n",
    "  Ransomware       0.90      0.92      0.91     14967\n",
    "    accuracy                           0.93     42559\n",
    "   macro avg       0.93      0.93      0.93     42559\n",
    "weighted avg       0.93      0.93      0.93     42559\n",
    "con\n",
    "dtype: int64\n",
    "Label\n",
    "Benigno       137907\n",
    "Ransomware     74888\n",
    "dtype: int64\n",
    "Precisión Modelo entrenado (Accuracy) :  90.92 %\n",
    "Precisión Modelo validado (Accuracy) :  91.02 %\n",
    "Matriz de Confusión AD Validada :\n",
    "[[25505  1958]\n",
    " [ 1865 13231]]\n",
    "Métricas AD Validadas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.93      0.93      0.93     27463\n",
    "  Ransomware       0.87      0.88      0.87     15096\n",
    "    accuracy                           0.91     42559\n",
    "   macro avg       0.90      0.90      0.90     42559\n",
    "weighted avg       0.91      0.91      0.91     42559\n",
    "sin\n",
    "[8 rows x 16 columns]\n",
    "Label\n",
    "Benigno    137907\n",
    "Malware    155426\n",
    "dtype: int64\n",
    "Precisión Modelo entrenado (Accuracy) :  92.97 %\n",
    "Precisión Modelo validado (Accuracy) :  92.84 %\n",
    "Matriz de Confusión AD Validada :\n",
    "[[25765  2027]\n",
    " [ 2171 28704]]\n",
    "Métricas AD Validadas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.92      0.93      0.92     27792\n",
    "     Malware       0.93      0.93      0.93     30875\n",
    "    accuracy                           0.93     58667\n",
    "   macro avg       0.93      0.93      0.93     58667\n",
    "weighted avg       0.93      0.93      0.93     58667\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
