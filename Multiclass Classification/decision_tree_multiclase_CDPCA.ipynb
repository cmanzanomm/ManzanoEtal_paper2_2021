{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign-2c .csv', 'malware.csv']\n",
      "   Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  TotLen_Fwd_Pkts  \\\n",
      "0           5870             2             0              813   \n",
      "1           1499             2             0              128   \n",
      "2             16             0             2                0   \n",
      "3          46435             1             1               79   \n",
      "4              0             1             0              356   \n",
      "\n",
      "   TotLen_Bwd_Pkts  Fwd_Pkt_Len_Min  Bwd_Pkt_Len_Min  Fwd_Pkt_Len_Max  \\\n",
      "0                0               83             -1.0              730   \n",
      "1                0               64             -1.0               64   \n",
      "2              159               -1             52.0               -1   \n",
      "3               95               79             95.0               79   \n",
      "4                0              356             -1.0              356   \n",
      "\n",
      "   Bwd_Pkt_Len_Max  Fwd_Pkt_Len_Mean  Bwd_Pkt_Len_Mean  Fwd_Pkt_Len_Std  \\\n",
      "0               -1             406.5               0.0       457.496995   \n",
      "1               -1              64.0               0.0         1.000000   \n",
      "2              107               0.0              79.5         0.000000   \n",
      "3               95              79.0              95.0         0.000000   \n",
      "4               -1             356.0               0.0         0.000000   \n",
      "\n",
      "   Bwd_Pkt_Len_Std    Flow_Pkts/s   Flow_Byts/s  Label  \n",
      "0         0.000000     340.715503  1.385009e+05      1  \n",
      "1         0.000000    1334.222815  8.539026e+04      1  \n",
      "2        38.878014  125000.000000  9.937500e+06      1  \n",
      "3         0.000000      43.070959  3.747173e+03      1  \n",
      "4         0.000000       0.000000  0.000000e+00      1  \n",
      "Cantidad de Filas y columnas: (293333, 16)\n",
      "Nombre columnas: Index(['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
      "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
      "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
      "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
      "       'Flow_Byts/s', 'Label'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 293333 entries, 0 to 293332\n",
      "Data columns (total 16 columns):\n",
      "Flow_Duration       293333 non-null int64\n",
      "Tot_Fwd_Pkts        293333 non-null int64\n",
      "Tot_Bwd_Pkts        293333 non-null int64\n",
      "TotLen_Fwd_Pkts     293333 non-null int64\n",
      "TotLen_Bwd_Pkts     293333 non-null int64\n",
      "Fwd_Pkt_Len_Min     293333 non-null int64\n",
      "Bwd_Pkt_Len_Min     293333 non-null float64\n",
      "Fwd_Pkt_Len_Max     293333 non-null int64\n",
      "Bwd_Pkt_Len_Max     293333 non-null int64\n",
      "Fwd_Pkt_Len_Mean    293333 non-null float64\n",
      "Bwd_Pkt_Len_Mean    293333 non-null float64\n",
      "Fwd_Pkt_Len_Std     293333 non-null float64\n",
      "Bwd_Pkt_Len_Std     293333 non-null float64\n",
      "Flow_Pkts/s         293333 non-null float64\n",
      "Flow_Byts/s         293333 non-null float64\n",
      "Label               293333 non-null int64\n",
      "dtypes: float64(7), int64(9)\n",
      "memory usage: 35.8 MB\n",
      "None\n",
      "       Flow_Duration  Tot_Fwd_Pkts   Tot_Bwd_Pkts  TotLen_Fwd_Pkts  \\\n",
      "count   2.933330e+05  2.933330e+05  293333.000000     2.933330e+05   \n",
      "mean    2.828950e+07  3.864145e+04       6.313695     1.112911e+03   \n",
      "std     1.999058e+08  6.429386e+06     157.698740     2.336930e+04   \n",
      "min    -1.800000e+01  0.000000e+00       0.000000     0.000000e+00   \n",
      "25%     0.000000e+00  1.000000e+00       0.000000     1.560000e+02   \n",
      "50%     5.129100e+04  4.000000e+00       2.000000     4.360000e+02   \n",
      "75%     5.481253e+06  1.400000e+01       6.000000     1.499000e+03   \n",
      "max     1.154108e+10  3.318803e+09   53758.000000     1.220839e+07   \n",
      "\n",
      "       TotLen_Bwd_Pkts  Fwd_Pkt_Len_Min  Bwd_Pkt_Len_Min  Fwd_Pkt_Len_Max  \\\n",
      "count     2.933330e+05    293333.000000    293333.000000    293333.000000   \n",
      "mean      1.010601e+04       244.073674        47.039805       255.224335   \n",
      "std       2.284979e+05       330.940856        92.317203       313.704548   \n",
      "min       0.000000e+00        -1.000000        -1.000000        -1.000000   \n",
      "25%       0.000000e+00        52.000000        -1.000000        52.000000   \n",
      "50%       1.306000e+03       182.000000        -1.000000        67.000000   \n",
      "75%       1.356200e+04       420.000000        52.000000       420.000000   \n",
      "max       7.463559e+07    126552.000000      1390.000000      1500.000000   \n",
      "\n",
      "       Bwd_Pkt_Len_Max  Fwd_Pkt_Len_Mean  Bwd_Pkt_Len_Mean  Fwd_Pkt_Len_Std  \\\n",
      "count    293333.000000     293333.000000     293333.000000    293333.000000   \n",
      "mean        202.769259        150.490722        115.501735        64.051232   \n",
      "std         387.007184        153.853141        218.544111       137.841367   \n",
      "min          -1.000000          0.000000          0.000000         0.000000   \n",
      "25%          -1.000000         52.000000          0.000000         0.000000   \n",
      "50%          -1.000000         65.000000          0.000000         1.000000   \n",
      "75%         217.000000        218.666667        113.000000        21.897488   \n",
      "max        1390.000000       1390.000000       1390.000000       954.593631   \n",
      "\n",
      "       Bwd_Pkt_Len_Std   Flow_Pkts/s   Flow_Byts/s          Label  \n",
      "count    293333.000000  2.933330e+05  2.933330e+05  293333.000000  \n",
      "mean         69.603111  3.504063e+04  1.825474e+06       2.175708  \n",
      "std         164.955297  1.761520e+05  9.649653e+06       1.263217  \n",
      "min           0.000000  0.000000e+00  0.000000e+00       1.000000  \n",
      "25%           0.000000  0.000000e+00  0.000000e+00       1.000000  \n",
      "50%           0.000000  6.960604e-01  8.643605e+01       2.000000  \n",
      "75%           4.564355  5.964630e+01  6.409914e+03       4.000000  \n",
      "max         946.108345  2.000000e+06  7.440000e+08       4.000000  \n",
      "Label\n",
      "1    123500\n",
      "2     40866\n",
      "3     39672\n",
      "4     41100\n",
      "dtype: int64\n",
      "Precisión Modelo entrenado (Accuracy) :  85.5 %\n",
      "Precisión Modelo validado (Accuracy) :  85.67 %\n",
      "Matriz de Confusión AD Validada :\n",
      "[[23178   537   502   570]\n",
      " [  726  6833    76   461]\n",
      " [  600    36  6793   506]\n",
      " [  972   593  1449  5196]]\n",
      "Métricas AD Validadas\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.94      0.92     24787\n",
      "           2       0.85      0.84      0.85      8096\n",
      "           3       0.77      0.86      0.81      7935\n",
      "           4       0.77      0.63      0.70      8210\n",
      "\n",
      "    accuracy                           0.86     49028\n",
      "   macro avg       0.83      0.82      0.82     49028\n",
      "weighted avg       0.85      0.86      0.85     49028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" ARBOL CON multiclase BINARIA BENIGNOS Y MALWARE\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report \n",
    "import os\n",
    "import glob\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"crea entorno grÃ¡fico\"\"\"\n",
    "plt.rcParams['figure.figsize'] = (40, 50)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Primero especificamos un patrón del archivo y lo pasamos como parámetro en la función glob\n",
    "os.chdir(\"..\\\\Datasets\")\n",
    "os.getcwd()\n",
    "csv_files = glob.glob('*.csv')\n",
    "# Mostrar el archivo csv_files, el cual es una lista de nombres\n",
    "print(csv_files)\n",
    "\n",
    "list_data = []\n",
    "  \n",
    "# Escribimos un loop que irá a través de cada uno de los nombres de archivo a través de globbing y el resultado final será la lista dataframes\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "#Para chequear que todo está bien, mostramos la list_data por consola\n",
    "#list_data\n",
    " \n",
    "df = pd.concat(list_data,ignore_index=True)\n",
    "\n",
    "tipos=df.dtypes  #tipos de datos de campos\n",
    "\n",
    "\"\"\"información datos\"\"\"\n",
    "print(df.head(5))\n",
    "print('Cantidad de Filas y columnas:',df.shape)\n",
    "print('Nombre columnas:',df.columns)\n",
    "\n",
    "\"\"\"Columnas, nulos y tipo de datos\"\"\"\n",
    "print(df.info())\n",
    "\n",
    "\"\"\"descripción estadística de los datos numéricos\"\"\"\n",
    "print(df.describe())\n",
    "\n",
    "\"\"\"correlación entre los datos\"\"\"\n",
    "corr = df.set_index('Label').corr()\n",
    "#sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
    "#plt.show()\n",
    "\n",
    "df2=df[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']]\n",
    "df3=df[['Label']]\n",
    "\n",
    "\"\"\"convertir columna tipo dato str a int\"\"\"\n",
    "df2['Label']=df3[['Label']]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "bines = 4 # Elegir el número de bines\n",
    "cabecera = list(df2) # Guardamos los nombres de las columnas.\n",
    "ind = 0 # Contador para iterar por columnas.\n",
    "while (ind < len(cabecera)):\n",
    "    disc = df2.iloc[:,ind] \n",
    "    disc = disc.to_frame() \n",
    "    disc = KBinsDiscretizer(n_bins=bines, encode='ordinal',\n",
    "                            strategy = \"quantile\").fit_transform(disc)\n",
    "    df2[cabecera[ind]] = disc \n",
    "    ind = ind + 1\n",
    "    del(disc)   \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"desordena el dataset\"\"\"\n",
    "\"\"\"desordena el dataset\"\"\"\n",
    "\n",
    "df2=df2.sort_values('Fwd_Pkt_Len_Min')\n",
    "df2 = df2[df2['Label'].isin([1,2,3,4])]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" convertir valores número la clase\n",
    "df2['Label'] = df2['Label'].replace(1,\"Benigno\")\n",
    "df2['Label'] = df2['Label'].replace(2,\"Adware\")\n",
    "df2['Label'] = df2['Label'].replace(3,\"Scareware\")\n",
    "df2['Label'] = df2['Label'].replace(4,\"Ransomware\")\n",
    "#print(df2.head(10))\n",
    "#print(df2.groupby('Label').size())\n",
    "\"\"\"\n",
    "\n",
    "dff=df2[:]\n",
    "dff1 = dff[dff.Label == 4]\n",
    "dff = dff.drop(dff[dff['Label'] == 4].index)\n",
    "a = dff1.iloc[0:41100,]\n",
    "dff2 = pd.concat([dff,a])\n",
    "\n",
    "dff=dff2[:]\n",
    "dff1 = dff[dff.Label == 1]\n",
    "dff = dff.drop(dff[dff['Label'] == 1].index)\n",
    "a = dff1.iloc[0:123500,]\n",
    "dff2 = pd.concat([dff,a])\n",
    "\n",
    "print(dff2.groupby('Label').size())\n",
    "\n",
    "\"\"\"CREAMOS EL MODELO Y LO PROBAMOS CON LOS MISMOS DATOS SIN CROSS\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def clean_dataset(df):\n",
    "       assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "       df.dropna(inplace=True)\n",
    "       indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "       return df[indices_to_keep].astype(np.float64)\n",
    "clean_dataset(dff2)   \n",
    "\"\"\"\n",
    "dff2 = dff2.fillna(lambda x: x.median())\n",
    "\n",
    "\n",
    "# example of a standardization\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#scaler = StandardScaler()\n",
    "#dff2 = scaler.fit_transform(dff2)\n",
    "#trans = MinMaxScaler()\n",
    "#dff2 = trans.fit_transform(dff2)\n",
    "\n",
    "\n",
    "   \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dff2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', \n",
    "\t   ]], dff2['Label'], test_size = 0.20, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "clf2 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best')#presort=False,\n",
    "\n",
    "\n",
    "\n",
    "#entreno modelo\n",
    "\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "acc_decision_tree = round(clf2.score(X_train, Y_train) * 100, 2)\n",
    "print(\"Precisión Modelo entrenado (Accuracy) : \", acc_decision_tree, \"%\")\n",
    "acc_decision_tree = round(clf2.score(X_test, Y_test) * 100, 2)\n",
    "print(\"Precisión Modelo validado (Accuracy) : \", acc_decision_tree, \"%\")\n",
    "\n",
    "#Realizo una predicción\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "\n",
    "matriz = confusion_matrix(Y_test, y_pred2)\n",
    "print('Matriz de Confusión AD Validada :')\n",
    "print(matriz)\n",
    "\n",
    "print(\"Métricas AD Validadas\")\n",
    "print(classification_report(Y_test, y_pred2))\n",
    "\n",
    "\n",
    "\n",
    "#classifier=OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "#y_score = classifier.fit(X_train, Y_train).decision_function (X_test)\n",
    "classifier=OneVsRestClassifier(DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best'))\n",
    "y_score = classifier.fit(X_train, Y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(17, 6)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "plot_multiclass_roc(classifier, X_test, Y_test, n_classes=4, figsize=(16, 10))\n",
    "\n",
    "\n",
    "\"\"\"=============================================\"\"\"\n",
    "\"\"\" CROSS VALIDATION\"\"\"\n",
    "\n",
    "X_trainCV, X_testCV, Y_trainCV, Y_testCV = train_test_split(dff2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', \n",
    "\t   ]],dff2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "clfCV = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best')\n",
    "clfCV.fit(X_train, Y_train)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "score = clfCV.score(X_trainCV,Y_trainCV)\n",
    "print(\"Metrica del modelo\", score * 100)\n",
    "scores = cross_val_score(clfCV, X_trainCV, Y_trainCV, cv=kf, scoring=\"accuracy\")\n",
    "print(\"Metricas cross_validation\", scores * 100)\n",
    "#print(\"Media de cross_validation\", scores.mean() * 100)\n",
    "preds = clfCV.predict(X_testCV)\n",
    "score_pred = metrics.accuracy_score(Y_testCV, preds)\n",
    "print(\"Metrica en Test\", score_pred * 100)\n",
    "conf_mat = confusion_matrix(Y_testCV, preds)\n",
    "print(conf_mat)\n",
    "print(classification_report(Y_testCV, preds))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#classifierCV=OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "#y_score = classifierCV.fit(X_train, Y_train).decision_function(X_test)\n",
    "\n",
    "classifierCV=OneVsRestClassifier(DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best'))\n",
    "y_score = classifierCV.fit(X_train, Y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(17, 6)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "#plot_multiclass_roc(classifierCV, X_test, Y_test, n_classes=4, figsize=(16, 10))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dtype: int64\n",
    "Precisión Modelo entrenado (Accuracy) :  93.48 %\n",
    "Precisión Modelo validado (Accuracy) :  93.45 %\n",
    "Matriz de Confusión AD Validada :\n",
    "[[26036  1556]\n",
    " [ 1233 13734]]\n",
    "Métricas AD Validadas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.95      0.94      0.95     27592\n",
    "  Ransomware       0.90      0.92      0.91     14967\n",
    "    accuracy                           0.93     42559\n",
    "   macro avg       0.93      0.93      0.93     42559\n",
    "weighted avg       0.93      0.93      0.93     42559\n",
    "con\n",
    "dtype: int64\n",
    "Label\n",
    "Benigno       137907\n",
    "Ransomware     74888\n",
    "dtype: int64\n",
    "Precisión Modelo entrenado (Accuracy) :  90.92 %\n",
    "Precisión Modelo validado (Accuracy) :  91.02 %\n",
    "Matriz de Confusión AD Validada :\n",
    "[[25505  1958]\n",
    " [ 1865 13231]]\n",
    "Métricas AD Validadas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.93      0.93      0.93     27463\n",
    "  Ransomware       0.87      0.88      0.87     15096\n",
    "    accuracy                           0.91     42559\n",
    "   macro avg       0.90      0.90      0.90     42559\n",
    "weighted avg       0.91      0.91      0.91     42559\n",
    "sin\n",
    "[8 rows x 16 columns]\n",
    "Label\n",
    "Benigno    137907\n",
    "Malware    155426\n",
    "dtype: int64\n",
    "Precisión Modelo entrenado (Accuracy) :  92.97 %\n",
    "Precisión Modelo validado (Accuracy) :  92.84 %\n",
    "Matriz de Confusión AD Validada :\n",
    "[[25765  2027]\n",
    " [ 2171 28704]]\n",
    "Métricas AD Validadas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.92      0.93      0.92     27792\n",
    "     Malware       0.93      0.93      0.93     30875\n",
    "    accuracy                           0.93     58667\n",
    "   macro avg       0.93      0.93      0.93     58667\n",
    "weighted avg       0.93      0.93      0.93     58667\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
