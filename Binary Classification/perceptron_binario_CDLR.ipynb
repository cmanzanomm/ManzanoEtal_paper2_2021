{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"analisis de malware y benigno con dataset y multilayer\n",
    "preprocesado por chinos con binario\n",
    "paper 244802 en df 293333\n",
    "https://datascience.stackexchange.com/questions/36049/how-to-adjust-the-hyperparameters-\n",
    "of-mlp-classifier-to-get-more-perfect-performa\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\"\"\"crea entorno grÃ¡fico\"\"\"\n",
    "plt.rcParams['figure.figsize'] = (40, 50)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Primero especificamos un patrón del archivo y lo pasamos como parámetro en la función glob\n",
    "os.chdir(\"..\\\\Datasets\")\n",
    "os.getcwd()\n",
    "csv_files = glob.glob('*.csv')\n",
    "# Mostrar el archivo csv_files, el cual es una lista de nombres\n",
    "print(csv_files)\n",
    "\n",
    "list_data = []\n",
    "  \n",
    "# Escribimos un loop que irá a través de cada uno de los nombres de archivo a través de globbing y el resultado final será la lista dataframes\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "#Para chequear que todo está bien, mostramos la list_data por consola\n",
    "#list_data\n",
    " \n",
    "df = pd.concat(list_data,ignore_index=True)\n",
    "\n",
    "tipos=df.dtypes  #tipos de datos de campos\n",
    "\n",
    "\"\"\"información datos\"\"\"\n",
    "print(df.head(5))\n",
    "print('Cantidad de Filas y columnas:',df.shape)\n",
    "print('Nombre columnas:',df.columns)\n",
    "\n",
    "\"\"\"Columnas, nulos y tipo de datos\"\"\"\n",
    "print(df.info())\n",
    "\n",
    "\"\"\"descripción estadística de los datos numéricos\"\"\"\n",
    "print(df.describe())\n",
    "\n",
    "\"\"\"correlación entre los datos\"\"\"\n",
    "corr = df.set_index('Label').corr()\n",
    "#sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
    "#plt.show()\n",
    "\n",
    "df2=df[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']]\n",
    "df3=df[['Label']]\n",
    "\n",
    "\"\"\"convertir columna tipo dato str a int\"\"\"\n",
    "df2['Label']=df3[['Label']]\n",
    "\n",
    "\"\"\"desordena el dataset\"\"\"\n",
    "\n",
    "df2=df2.sort_values('Fwd_Pkt_Len_Min')\n",
    "df2 = df2[df2['Label'].isin([1,2,3,4])]\n",
    "\n",
    "\"\"\" convertir valores número la clase\"\"\"\n",
    "df2['Label'] = df2['Label'].replace(1,\"Benigno\")\n",
    "df2['Label'] = df2['Label'].replace(2,\"Malware\")\n",
    "df2['Label'] = df2['Label'].replace(3,\"Malware\")\n",
    "df2['Label'] = df2['Label'].replace(4,\"Malware\")\n",
    "#print(df2.head(10))\n",
    "#print(df2.groupby('Label').size())\n",
    "\n",
    "\n",
    "dff=df2[:]\n",
    "dff1 = dff[dff.Label == 'Malware']\n",
    "dff = dff.drop(dff[dff['Label'] == 'Malware'].index)\n",
    "a = dff1.iloc[0:134800,]\n",
    "df2 = pd.concat([dff,a])\n",
    "\n",
    "\n",
    "\n",
    "print(df2.groupby('Label').size())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"CREAMOS EL MODELO Y LO PROBAMOS CON LOS MISMOS DATOS SIN CROSS\"\"\"\n",
    "\n",
    "\n",
    "# Split dataset in training and test datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', \n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']],df2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "\n",
    "    \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "clf =MLPClassifier(max_iter=60)\n",
    "\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "accuracy = clf.score(X_train, Y_train) *100\n",
    "print(\"Precision entrenamiento: \"+ str(accuracy))\n",
    "\n",
    "predictions = clf.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = clf.score(X_test, Y_test) *100\n",
    "print(\"Precision validado: \"+ str(accuracy))\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(Y_test, predictions) \n",
    "print(cm)\n",
    "print(\"Métricas\")\n",
    "print(classification_report(Y_test, predictions))\n",
    "\n",
    "\"\"\" convierto valor nombre a 0=benigno 1=malware para AUC-ROC\"\"\"\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df2.iloc[:,15] = label_encoder.fit_transform(df2.iloc[:,15]).astype('int64')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', \n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']],df2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "\n",
    "def plot_roc(model, X_test, Y_test):\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probabilities = model.predict_proba(np.array(X_test))\n",
    "    predictions = probabilities[:, 1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(clf, X_test, Y_test)\n",
    "\n",
    "\n",
    "\"\"\"=============================================\"\"\"\n",
    "\"\"\" CROSS VALIDATION\"\"\"\n",
    "\n",
    "X_trainCV, X_testCV, Y_trainCV, Y_testCV = train_test_split(df2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', \n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']],df2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "\n",
    "clfCV = MLPClassifier(max_iter=60)\n",
    "clfCV.fit(X_trainCV, Y_trainCV)\n",
    "kf = KFold(n_splits=10)\n",
    "score = clfCV.score(X_trainCV,Y_trainCV)\n",
    "print(\"Metrica del modelo\", score * 100)\n",
    "scores = cross_val_score(clfCV, X_trainCV, Y_trainCV, cv=kf, scoring=\"accuracy\")\n",
    "print(\"Metricas cross_validation\", scores * 100)\n",
    "#print(\"Media de cross_validation\", scores.mean() * 100)\n",
    "preds = clfCV.predict(X_testCV)\n",
    "score_pred = metrics.accuracy_score(Y_testCV, preds)\n",
    "print(\"Metrica en Test\", score_pred * 100)\n",
    "conf_mat = confusion_matrix(Y_testCV, preds)\n",
    "print(conf_mat)\n",
    "print(classification_report(Y_testCV, preds))\n",
    "\n",
    "def plot_roc(model, X_test, Y_test):\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probabilities = model.predict_proba(np.array(X_test))\n",
    "    predictions = probabilities[:, 1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(clfCV, X_testCV, Y_testCV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sin\n",
    "Label\n",
    "Benigno    137907\n",
    "Malware    155426\n",
    "dtype: int64\n",
    "Precision entrenamiento: 78.16428455762659\n",
    "Precision validado: 78.23307822114647\n",
    "[[18597  8865]\n",
    " [ 3905 27300]]\n",
    "Métricas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.83      0.68      0.74     27462\n",
    "     Malware       0.75      0.87      0.81     31205\n",
    "    accuracy                           0.78     58667\n",
    "   macro avg       0.79      0.78      0.78     58667\n",
    "weighted avg       0.79      0.78      0.78     58667\n",
    "Label\n",
    "Benigno    137907\n",
    "Malware    155426\n",
    "dtype: int64\n",
    "Precision entrenamiento: 94.57612095488908\n",
    "Precision validado: 94.51309935739002\n",
    "[[25362  2194]\n",
    " [ 1025 30086]]\n",
    "Métricas\n",
    "              precision    recall  f1-score   support\n",
    "     Benigno       0.96      0.92      0.94     27556\n",
    "     Malware       0.93      0.97      0.95     31111\n",
    "    accuracy                           0.95     58667\n",
    "   macro avg       0.95      0.94      0.94     58667\n",
    "weighted avg       0.95      0.95      0.95     58667\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
