{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ARBOL CON CLASE BINARIA \"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\"\"\"crea entorno grÃ¡fico\"\"\"\n",
    "plt.rcParams['figure.figsize'] = (40, 50)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Primero especificamos un patrón del archivo y lo pasamos como parámetro en la función glob\n",
    "os.chdir(\"..\\\\Datasets\")\n",
    "os.getcwd()\n",
    "csv_files = glob.glob('*.csv')\n",
    "# Mostrar el archivo csv_files, el cual es una lista de nombres\n",
    "print(csv_files)\n",
    "\n",
    "list_data = []\n",
    "  \n",
    "# Escribimos un loop que irá a través de cada uno de los nombres de archivo a través de globbing y el resultado final será la lista dataframes\n",
    "\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    list_data.append(data)\n",
    "\n",
    "#Para chequear que todo está bien, mostramos la list_data por consola\n",
    "#list_data\n",
    " \n",
    "df = pd.concat(list_data,ignore_index=True)\n",
    "\n",
    "tipos=df.dtypes  #tipos de datos de campos\n",
    "\n",
    "\"\"\"información datos\"\"\"\n",
    "print(df.head(5))\n",
    "print('Cantidad de Filas y columnas:',df.shape)\n",
    "print('Nombre columnas:',df.columns)\n",
    "\n",
    "\"\"\"Columnas, nulos y tipo de datos\"\"\"\n",
    "print(df.info())\n",
    "\n",
    "\"\"\"descripción estadística de los datos numéricos\"\"\"\n",
    "print(df.describe())\n",
    "\n",
    "\"\"\"correlación entre los datos\"\"\"\n",
    "corr = df.set_index('Label').corr()\n",
    "#sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
    "#plt.show()\n",
    "\n",
    "df2=df[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']]\n",
    "df3=df[['Label']]\n",
    "\n",
    "\"\"\"convertir columna tipo dato str a int\"\"\"\n",
    "df2['Label']=df3[['Label']]\n",
    "\n",
    "\"\"\"desordena el dataset\"\"\"\n",
    "\n",
    "df2=df2.sort_values('Fwd_Pkt_Len_Min')\n",
    "df2 = df2[df2['Label'].isin([1,2,3,4])]\n",
    "\n",
    "\"\"\" convertir valores número la clase\"\"\"\n",
    "df2['Label'] = df2['Label'].replace(1,\"Benigno\")\n",
    "df2['Label'] = df2['Label'].replace(2,\"Malware\")\n",
    "df2['Label'] = df2['Label'].replace(3,\"Malware\")\n",
    "df2['Label'] = df2['Label'].replace(4,\"Malware\")\n",
    "#print(df2.head(10))\n",
    "#print(df2.groupby('Label').size())\n",
    "\n",
    "\n",
    "dff=df2[:]\n",
    "dff1 = dff[dff.Label == 'Malware']\n",
    "dff = dff.drop(dff[dff['Label'] == 'Malware'].index)\n",
    "a = dff1.iloc[0:134800,]\n",
    "df2 = pd.concat([dff,a])\n",
    "\n",
    "\n",
    "\n",
    "print(df2.groupby('Label').size())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"CREAMOS EL MODELO Y LO PROBAMOS CON LOS MISMOS DATOS SIN CROSS\"\"\"\n",
    "\n",
    "#con np.array para otra cosa\n",
    "#X = np.array(df2.drop(['Label'],1))\n",
    "#y = np.array(df2['Label'])\n",
    "\n",
    "#X = df2.drop(['Label'], axis=1)\n",
    "#y = df2['Label']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Split dataset in training and test datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']],df2['Label'], test_size=0.2, random_state=6) \n",
    "\"\"\"\n",
    "clf2 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       random_state=0, splitter='best')#presort=False,\n",
    "\"\"\"\n",
    "clf2 = DecisionTreeClassifier()\n",
    "#entreno modelo\n",
    "\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "acc_decision_tree = round(clf2.score(X_train, Y_train) * 100, 2)\n",
    "print(\"Precisión Modelo entrenado (Accuracy) : \", acc_decision_tree, \"%\")\n",
    "acc_decision_tree = round(clf2.score(X_test, Y_test) * 100, 2)\n",
    "print(\"Precisión Modelo validado (Accuracy) : \", acc_decision_tree, \"%\")\n",
    "\n",
    "#Realizo una predicción\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "\n",
    "matriz = confusion_matrix(Y_test, y_pred2)\n",
    "print('Matriz de Confusión AD Validada :')\n",
    "print(matriz)\n",
    "\n",
    "print(\"Métricas AD Validadas\")\n",
    "print(classification_report(Y_test, y_pred2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" convierto valor nombre a 0=benigno 1=malware para AUC-ROC\"\"\"\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df2.iloc[:,15] = label_encoder.fit_transform(df2.iloc[:,15]).astype('int64')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']],df2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "\n",
    "def plot_roc(model, X_test, Y_test):\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probabilities = model.predict_proba(np.array(X_test))\n",
    "    predictions = probabilities[:, 1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(clf2, X_test, Y_test)\n",
    "\n",
    "\n",
    "\"\"\"=============================================\"\"\"\n",
    "\"\"\" CROSS VALIDATION\"\"\"\n",
    "\n",
    "X_trainCV, X_testCV, Y_trainCV, Y_testCV = train_test_split(df2[['Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts',\n",
    "       'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Min',\n",
    "       'Fwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Mean',\n",
    "       'Bwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std', 'Bwd_Pkt_Len_Std', 'Flow_Pkts/s',\n",
    "       'Flow_Byts/s']],df2['Label'], test_size=0.2, random_state=6) \n",
    "\n",
    "\n",
    "clfCV = DecisionTreeClassifier()\n",
    "clfCV.fit(X_trainCV, Y_trainCV)\n",
    "kf = KFold(n_splits=10)\n",
    "score = clfCV.score(X_trainCV,Y_trainCV)\n",
    "print(\"Metrica del modelo\", score * 100)\n",
    "scores = cross_val_score(clfCV, X_trainCV, Y_trainCV, cv=kf, scoring=\"accuracy\")\n",
    "print(\"Metricas cross_validation\", scores * 100)\n",
    "#print(\"Media de cross_validation\", scores.mean() * 100)\n",
    "preds = clfCV.predict(X_testCV)\n",
    "score_pred = metrics.accuracy_score(Y_testCV, preds)\n",
    "print(\"Metrica en Test\", score_pred * 100)\n",
    "conf_mat = confusion_matrix(Y_testCV, preds)\n",
    "print(conf_mat)\n",
    "print(classification_report(Y_testCV, preds))\n",
    "\n",
    "def plot_roc(model, X_test, Y_test):\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probabilities = model.predict_proba(np.array(X_test))\n",
    "    predictions = probabilities[:, 1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(clfCV, X_testCV, Y_testCV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
